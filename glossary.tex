% From here: https://en.m.wikibooks.org/wiki/LaTeX/Glossary
% Example use:
%\newdualentry{OWD} % label
%{OWD}            % abbreviation
%{One-Way Delay}  % long form
%{The time a packet uses through a network from one host to another} % description
\usepackage{xparse}
\DeclareDocumentCommand{\newdualentry}{ O{} O{} m m m m } {
  \newglossaryentry{gls-#3}{name={#5},text={#5\glsadd{#3}},
    description={#6},#1
  }
  \makeglossaries
  \newacronym[see={[Glossary:]{gls-#3}},#2]{#3}{#4}{#5\glsadd{gls-#3}}
}

\newdualentry{cnn}{CNN}{Convolutional Neural Network}{A neural network designed for learning representations of image inputs, with shared parameters in the form of a set of convolutional filters}
\newdualentry{dnn}{DNN}{Deep Neural Network}{A neural network with two or more hidden layers}
\newdualentry{rnn}{RNN}{Recurrent Neural Network}{A neural network designed for sequences, with shared parameters in the form of a recurrence}
\newdualentry{cifar}{CIFAR}{Canadian Institute for Advanced Research}{Government agency behind the funding of several prominent researchers in Canada, notably the lab of Geoffery Hinton who released two popular datasets, \acrshort{cifar10} and CIFAR100}
\newdualentry{mnist}{MNIST}{Modified National Institute of Standards and Technology}{Dataset of handwritten numerical digits commonly used as a 60,000 image training/10,000 image testing dataset for machine learning algorithms}
\newdualentry{mlp}{MLP}{Multi-layer Perceptron}{An established misnomyer for a neural network with one or more hidden layers, not related to a Perceptron}
\newdualentry{vgg}{VGG}{Visual Geometry Group}{A research group at the University of Oxford in which the popular VGG network architecture was developed by \citep{Simonyan2014verydeep}}
\newdualentry{nin}{NiN}{Network in Network}{A neural network architecture proposed by \citet{Lin2014} which introduced \acrshort{gap} and \acrshort{lde}}
\newdualentry{blas}{BLAS}{Basic Linear Algebra Subprograms}{A common \acryshort{api} for accelerating linear algebra operations, notably matrix multiplication, on hardware. Typically a heavily optimized version is provided by the hardware company.}
\newdualentry{cublas}{CuBLAS}{CUDA BLAS}{Nvidia's implementation of \acryshort{blas} for the \acryshort{cuda} \acryshort{GPU} programming \acryshort{api}}
\newdualentry{cuda}{CUDA}{CUDA BLAS}{Nvidia's \acryshort{GPU} programming \acryshort{api}}

\newglossaryentry{cifar10}{name=CIFAR-10, description={An image recognition dataset created by \citet{CIFAR10} consisting of 60,000 32$\times$32 colour images of 10 classes of objects}}
%\newglossaryentry{cifar100}{name=CIFAR-100, description={An image recognition dataset created by \citet{CIFAR10} consisting of 60,000 32$\times$32 colour images of 100 classes of objects}}
\newglossaryentry{alexnet}{name=AlexNet, description={A neural network architecture proposed by \citet{Krizhevsky2012} that revolutionized computer vision, and renewed interest in neural networks}}
\newglossaryentry{googlenet}{name=GoogLeNet, description={A neural network architecture proposed by \citet{Szegedy2014going} and since extended in the Inception v1--4 refinements}}
\newglossaryentry{inception}{name=Inception, description={A building-block of the GoogLeNet neural network architecture designed for efficient state-of-the-art image recognition}}
\newglossaryentry{structuralprior}{name=Structural Prior, description={The encoding of prior knowledge of the problem into a neural network by architecture design, \eg{}a \acrshort{cnn}}}

\newacronym{relu}{ReLU}{Rectified Linear Unit}
\newacronym{pca}{PCA}{Principled Component Analysis}
\newacronym{gpu}{GPU}{Graphical Processing Unit}
\newacronym{cpu}{CPU}{Computer Processing Unit}
\newacronym{rgb}{RGB}{Red-Green-Blue}
\newacronym{nn}{NN}{Neural Network}
\newacronym{ilsvrc}{ILSVRC}{Imagenet Large-Scale Visual Recognition Challenge}
\newacronym{sgd}{SGD}{Stochastic Gradient Descent}
\newacronym{msr}{MSR}{Microsoft Research}
\newacronym{cvpr}{CVPR}{Computer Vision and Pattern Recognition}
\newacronym{iclr}{ICLR}{International Conference on Learning Representations}
\newacronym{lde}{LDE}{Low Dimensional Embeddings}
\newacronym{gap}{GAP}{Global Average Pooling}
\newacronym{gmp}{GMP}{Global Max Pooling}
\newacronym{vc}{VC}{Vapnik-Chervonenkis}
\newacronym{nfl}{NFL}{No Free Lunch theorem}
\newacronym{zca}{ZCA}{Zero Component Analysis}
\newacronym{ma}{MA}{Multiply-Accumulate}
\newacronym{flops}{FLOPS}{Floating Point Operations}
\newacronym{api}{API}{Application Programming Interface}