@comment{x-kbibtex-personnameformatting=<%f ><%l><, %s>}

@incollection{Bottou2012sgdtricks,
	author = "L{\'e}on Bottou",
	booktitle = "{Neural Networks: Tricks of the Trade (2nd ed.)}",
	editor = "Gr{\'e}goire Montavon and Genevieve B. Orr and Klaus-Robert M{\"u}ller",
	isbn = "978-3-642-35288-1",
	keywords = "dblp",
	pages = "421--436",
	publisher = "Springer",
	series = "{Lecture Notes in Computer Science}",
	title = "{Stochastic Gradient Descent Tricks.}",
	volume = 7700,
	year = 2012
}

@inproceedings{Krizhevsky2012imanet,
	author = "A. Krizhevsky and I. Sutskever and G. Hinton",
	booktitle = nips,
	title = "{Image{N}et Classification with Deep Convolutional Neural Networks}",
	year = "2012"
}

@inproceedings{Krizhevsky2014,
	author = "A. Krizhevsky",
	booktitle = "{eprint ar{X}iv:1404.5997v2}",
	title = "{One Weird Trick for Parallelizing Convolutional Neural Networks}",
	year = "2014"
}

@inproceedings{He2015delving,
	author = "K. He and X. Zhang and J. Sun",
	booktitle = "{eprint ar{X}iv:1502.01852v1}",
	title = "{Delving Deep into Rectifiers: Surpassing Human-Level Performance on Image{N}et Classification}",
	year = "2015"
}

@inproceedings{Simonyan2014verydeep,
	author = "K. Simonyan and A. Zisserman",
	booktitle = "{eprint ar{X}iv:arXiv:1409.1556v5}",
	title = "{Very Deep Convolutional networks for Large-Scale Image Recognition}",
	year = "2014"
}

@inproceedings{Wu2015scalingup,
	author = "R.Wu and S.Yan and Y.Shan and Q.Dang and G.Sun",
	booktitle = "{eprint ar{X}iv:1501.02876v2}",
	title = "{Deep Image: Scaling up Image Recognition}",
	year = "2015"
}

@inproceedings{Zhang2015efficient,
	author = "X. Zhang and J. Zou and X. Ming and K. He and J. Sun",
	booktitle = "{eprint ar{X}iv:1411.4229v1}",
	title = "{Efficient and Accurate Approximations of Nonlinear Convolutional Networks}",
	year = "2014"
}

@inproceedings{Denton2014efficient,
	author = "E. Denton and W. Zaremba and J. Bruna and Y. LeCun and R.Fergus",
	booktitle = "{eprint ar{X}iv:1404.0736v2}",
	title = "{Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation}",
	year = "2014"
}

@inproceedings{Zeiler2010Deconv,
	author = "M. D. Zeiler and D. Krishnan and G. W. Taylor and R.Fergus",
	booktitle = "{cvpr}",
	title = "{Deconvolutional Networks}",
	year = "2010"
}

@inproceedings{Luo2010switchable,
	author = "P. Luo and Y. Tian and X. Wang and X. Tang",
	booktitle = "{cvpr}",
	title = "{Switchable Deep Networks for Pedestrian Detection}",
	year = "2010"
}

@inproceedings{Sermanet2013overfeat,
	author = "P. Sermanet and D. Eigen and X. Zhang and M. Mathieu and R. Fergus and Y. LeCun",
	booktitle = "{eprint ar{X}iv:1312.6229}",
	title = "{OverFeat: Integrated Recognition, localization and Detection using Convolutional Networks}",
	year = "2013"
}

@inproceedings{Ba2013dothey,
	author = "L. J. Ba and R. Caruana",
	booktitle = "{eprint ar{X}iv:1312.6184v5}",
	title = "{Do Deep Nets Really Need to be Deep}",
	year = "2013"
}

@inproceedings{Szegedy2014going,
	author = "C. Szegedy and W. Liu and Y. Jia and P. Sermanet and S. Reed and D. Anguelov and D. Erhan and V. Vanhoucke and A. Rabinovich",
	booktitle = "{eprint ar{X}iv:1409.4842}",
	title = "{Going Deeper with Convolutions}",
	year = "2014"
}

@inproceedings{Bengio2010labeltree,
	author = "S. Bengio and J. Weston and D. Grangier",
	booktitle = "{nips}",
	title = "{Label Embedding Trees for Large Multi-Class Tasks}",
	year = "2010"
}

@inproceedings{Deng2011fastbalanced,
	author = "J. Deng and S. Satheesh and A. C. Berg and F.-F. Li",
	booktitle = "{nips}",
	title = "{Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition}",
	year = "2011"
}

@inproceedings{Deselaers2011visual,
	author = "V. Ferrari {T. Deselaers}",
	booktitle = "{cvpr}",
	title = "{Visual and Semantic Similarity in {I}mage{N}et}",
	year = "2011"
}

@inproceedings{Denil2013predicting,
	author = "M. Denil and B. Shakibi and L. Dinh and M. A. Ranzato and N deFreitas",
	booktitle = "{eprint ar{X}iv:1306.0543v2}",
	title = "{Predicting Parameters in Deep Learning}",
	year = "2013"
}

@techreport{Sethi1990,
	author = "I. K. Sethi",
	institution = "Dept. of Computer Sci, Wayne State Univ., Detroit, MI",
	title = "{Entropy nets: from decision trees to neural networks}",
	year = "1990"
}

@inproceedings{Welbl2014casting,
	author = "J. Welbl",
	booktitle = "{GCPR}",
	title = "{Casting Random Forests as Artificial Neural Networks (and Profiting from It)}",
	year = "2014"
}

@book{yu2014book,
	author = "D. Yu and L. Deng",
	publisher = "Springer",
	title = "{Automatic Speech Recognition: A Deep Learning Approach}",
	year = "2014"
}

@inproceedings{Sutskever2013momentum,
	author = "I. Sutskever and J. Martens and G. Dahl and G. Hinton",
	booktitle = icml,
	title = "{On the importance of initialization and momentum in deep learning}",
	year = "2013"
}

@inproceedings{Jia2014caffe,
	author = "Y. Jia and E. Shelhamer and J. Donahue and S. Karayev and J. Long and R. Girshick and S. Guadarrama and T. Darrell",
	booktitle = "{eprint ar{X}iv:arXiv:1408.5093}",
	title = "{Caffe: Convolutional Architecture for Fast Feature Embedding}",
	year = "2014"
}

@article{lee2014deeply,
	author = "Chen-Yu Lee and Saining Xie and Patrick Gallagher and Zhengyou Zhang and Zhuowen Tu",
	journal = "arXiv preprint arXiv:1409.5185",
	title = "{Deeply-supervised nets}",
	year = "2014"
}

@article{ILSVRC2015,
	author = "Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei",
	doi = "10.1007/s11263-015-0816-y",
	journal = "International Journal of Computer Vision (IJCV)",
	title = "{ImageNet Large Scale Visual Recognition Challenge}",
	year = "2015"
}

@techreport{CIFAR10,
	author = "A. Krizhevsky",
	institution = "Univ. Toronto",
	title = "{Learning Multiple Layers of Features from Tiny Images}",
	type = "Technical Report",
	year = "2009"
}

@article{ieee7005506,
	abstract = "Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224224) input image. This requirement is ``artificial'' and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, ``spatial pyramid pooling'', to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-theart classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank \#2 in object detection and \#3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.",
	arnumber = "7005506",
	author = "K. He and X. Zhang and S. Ren and J. Sun",
	doi = "10.1109/TPAMI.2015.2389824",
	issn = "0162-8828",
	journal = "Pattern Analysis and Machine Intelligence, IEEE Transactions on",
	keywords = "Accuracy; Agriculture; Convolutional codes; Feature extraction; Testing; Training; Vectors; Convolutional Neural Networks; Image Classification; Object Detection; Spatial Pyramid Pooling",
	month = "",
	number = "99",
	pages = "1--1",
	title = "{Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}",
	volume = "PP",
	x-fetchedfrom = "IEEEXplore",
	year = "2015"
}

@misc{1406.4729v4,
	abstract = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. This requirement is "artificial" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, "spatial pyramid pooling", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102x faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank \#2 in object detection and \#3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
	archiveprefix = "arXiv",
	author = "Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun",
	comment = "published = 2014-06-18T14:24:17Z, updated = 2015-04-23T07:33:24Z, This manuscript is the accepted version for IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2015. See Changelog",
	eprint = "1406.4729v4",
	month = apr,
	primaryclass = "cs.CV",
	title = "{Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}",
	url = "http://arxiv.org/abs/1406.4729v4; http://arxiv.org/pdf/1406.4729v4",
	x-fetchedfrom = "arXiv.org",
	year = "2015"
}

@inproceedings{Oquab:2014:LTM:2679600.2680210,
	acmid = "2680210",
	address = "Washington, DC, USA",
	author = "Maxime Oquab and Leon Bottou and Ivan Laptev and Josef Sivic",
	booktitle = "{Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition}",
	doi = "10.1109/CVPR.2014.222",
	isbn = "978-1-4799-5118-5",
	numpages = "8",
	pages = "1717--1724",
	publisher = "IEEE Computer Society",
	series = "{CVPR '14}",
	title = "{Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks}",
	url = "http://dx.doi.org/10.1109/CVPR.2014.222",
	x-fetchedfrom = "ACM Digital Library",
	year = "2014"
}

@article{Lin2013NiN,
	added-at = "2014-06-05T19:00:44.000+0200",
	author = "Min Lin and Qiang Chen and Shuicheng Yan",
	interhash = "67da1ef3d0d91a16dbe3ec25474b9aaf",
	intrahash = "78171ed7a70a99e98b4e320a5b32b837",
	journal = "CoRR",
	keywords = "In Network",
	title = "{Network In Network.}",
	url = "http://dblp.uni-trier.de/db/journals/corr/corr1312.html#LinCY13; http://arxiv.org/abs/1312.4400; http://www.bibsonomy.org/bibtex/278171ed7a70a99e98b4e320a5b32b837/prlz77",
	volume = "abs/1312.4400",
	x-fetchedfrom = "Bibsonomy",
	year = 2013
}

@misc{1207.0580v1,
	abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
	archiveprefix = "arXiv",
	author = "Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov",
	comment = "published = 2012-07-03T06:35:15Z, updated = 2012-07-03T06:35:15Z",
	eprint = "1207.0580v1",
	month = jul,
	primaryclass = "cs.NE",
	title = "{Improving neural networks by preventing co-adaptation of feature detectors}",
	url = "http://arxiv.org/abs/1207.0580v1; http://arxiv.org/pdf/1207.0580v1",
	x-fetchedfrom = "arXiv.org",
	year = "2012"
}

