\documentclass[thesis]{subfiles}

\begin{document}

\chapter{Methodology}
\label{methodology}
% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Figs/Raster/}{Figs/PDF/}{Figs/}}
\else
    \graphicspath{{Figs/Vector/}{Figs/}}
\fi

\section{Generalising Neural Networks and Decision Trees}
Although the relationship between neural networks and decision trees has been explored in the past, in the case of Entropy Nets~\cite{Sethi1990} this was with the intention of training and creating neural networks with decision-tree approaches, while in the case of TODO~\cite{Welbl2014casting}.

Here we explore the relationship, with the objective of reducing the connectivity of deep neural networks trained with back-propagation, specifically convolutional neural networks. 

Towards this objective, we generalize neural networks and decision trees intuitively by using a new graphical notation for representing both. This notation isolates the differences between the two models, such that we can represent a hybrid model, i.e. Conditional Network, compactly\footnote{This notation itself was created by Dr. Antonio Criminisi, and is not a contribution of this thesis. Figures used with the permission of Dr. Antonio Criminisi and Microsoft Research.}.

\section{A New Graphical Notation}
The proposals we will make require a re-interpretation of existing classification models, that is neural networks and decision trees, but standard notation for both of these models hides the implicit similarities on which we will rely. As such, before we are able to explain the concept of a conditional network, a new graphical notation is proposed.

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{minion}
\caption[Minion]{This is just a long figure caption for the minion in Despicable Me from Pixar}
\label{fig:minion}
\end{figure}

The standard depiction of a neural network is shown in Fig.~\ref{standardnn}, 

\end{document}